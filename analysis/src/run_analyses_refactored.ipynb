{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_functions\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--colour_dict_dir\", type=str, help=\"output directory which should be used for generating first plotting colour dictionary (the largest dataset)\")\n",
    "parser.add_argument(\"--colour_dict_filename\", type=str, help=\"Filename to use for pickle of colour dict in /analysis/data\")\n",
    "parser.add_argument(\"--list_of_dirs\", type=str, help=\"comma-separated list of directories for which to do the plots and figures\")          \n",
    "parser.add_argument(\"--dir_info_pickle\", type=str, help='Filename to use for pickle of thresholds information dictionary in /analysis/data')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/scratch/ias41/ae_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_list = args.list_of_dirs.split(',')\n",
    "\n",
    "# Make sure the colour dict is run first\n",
    "if args.colour_dict_dir and args.colour_dict_dir in directory_list:\n",
    "    directory_list.remove(args.colour_dict_dir)\n",
    "    directory_list = [args.colour_dict_dir] + directory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donut sizes meaning:\n",
    "# 0: The number/count of AEs above which should be normal label display (not line to label)\n",
    "# 1: The number/count of AEs above which should start putting a line with label\n",
    "# 2: The number/count of AEs above which to display the count in the square of the donut\n",
    "# 3: Counting the donut squares with different colors, at which square should start the line labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dict({\n",
    "            '20200110_faers_unbound_margin_pred_005_PRR2': {'dir': '20200110_faers_unbound_margin_pred_005_PRR2'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [9,2,4,6]\n",
    "            , 'donut_white': [7,8,14,15,16]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "            '20191229_faers_unbound_margin_005_PRR2': {'dir': '20191229_faers_unbound_margin_005_PRR2'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [4,1,1,5]\n",
    "            , 'donut_white': [7,8,14,15,16]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "            '20200110_faers_total_margin_pred_005_PRR2': {'dir': '20200110_faers_total_margin_pred_005_PRR2'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [12,3,3,5]\n",
    "            , 'donut_white': [7,9,12]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "            '20200110_faers_cutoff6_pred_005_PRR2': {'dir': '20200110_faers_cutoff6_pred_005_PRR2'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [53,18,18,10]\n",
    "            , 'donut_white': [1,5,13,17]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "        '20200110_sider_unbound_margin_pred': {'dir': '20200110_sider_unbound_margin_pred'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [19,3,5,7]\n",
    "            , 'donut_white': [2,3,5,8,9,11]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "        '20191229_sider_unbound_margin': {'dir': '20191229_sider_unbound_margin'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [12,2,2,4]\n",
    "            , 'donut_white': [1,3,6,7]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "            '20200110_sider_total_margin_pred': {'dir': '20200110_sider_total_margin_pred'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [22,6,6,7]\n",
    "            , 'donut_white': [2,6,9]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            },\n",
    "            '20200110_sider_cutoff6_pred': {'dir': '20200110_sider_cutoff6_pred'\n",
    "            , 'min_n': 5\n",
    "            , 'lr': 2\n",
    "            , 'pv': 0.05\n",
    "            , 'top_lr': 2\n",
    "            , 'top_pv': 0.05\n",
    "            , 'ppv': 0                                \n",
    "            , 'hr': 0\n",
    "            , 'donut_sizes': [98,25,25,10]\n",
    "            , 'donut_white': [3,5,8,9,11]\n",
    "            , 'colour_dict': args.colour_dict_filename\n",
    "            , 'precision_display': 0.3                                 \n",
    "            }\n",
    "       }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir + '/analysis/data/dirs_info.pkl', 'wb') as f:\n",
    "    pickle.dump(dirs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    dirs[directory]['top_conditions_string'] = \"lr{}_pv{}_ppv{}_hr{}\".format(dirs[directory]['lr'], dirs[directory]['pv'], dirs[directory]['ppv'], dirs[directory]['hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and info needed for the analysis\n",
    "\n",
    "# Target information\n",
    "target_info = pd.read_csv(basedir + '/ae_target_links/data/target_names.txt', sep='\\t')\n",
    "target_info = target_info.loc[target_info['accession_organism']=='Homo sapiens',:]\n",
    "\n",
    "# MedDRA hierchy\n",
    "meddra_hier = pd.read_excel(basedir + '/analysis/data/all_faers_and_sider_aes_hier_output.xlsx', skiprows=4)\n",
    "meddra_hier_selection = meddra_hier.loc[meddra_hier['Primary SOC']=='Y',[' Term','HLT','SOC']].drop_duplicates()\n",
    "meddra_hier_selection['HLT'] = meddra_hier_selection['HLT'].apply(lambda x: x.upper())\n",
    "\n",
    "# ATC codes\n",
    "all_atc_codes_loc = basedir + '/faers_sider_comparison/data/atc_all.txt'\n",
    "small_molecule_atc_codes_loc = basedir + '/faers_sider_comparison/data/atc_small_molecules.txt'\n",
    "\n",
    "# Target classification\n",
    "chembl_target_classification = pd.read_csv(basedir + '/analysis/data/target_classification_all_levels_r.txt', sep = '\\t')\n",
    "\n",
    "# Previously reported associations\n",
    "# Known associations, merge with known hierarchy HLT\n",
    "known_associations = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_annotated_effects.xls')\n",
    "known_associations['Annotated MedDRA PT'] = known_associations['Annotated MedDRA PT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_annotated_effects_for_hierarchy_output.xlsx', skiprows=4)\n",
    "known_meddra_hier['PT'] = known_meddra_hier['PT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier[' Term'] = known_meddra_hier[' Term'].apply(lambda x: x.upper())\n",
    "known_meddra_hier['HLT'] = known_meddra_hier['HLT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier_selection = known_meddra_hier.loc[known_meddra_hier['Primary SOC']=='Y',['PT','HLT',' Term']].drop_duplicates()\n",
    "known_merged = known_associations.merge(known_meddra_hier_selection, left_on='Annotated MedDRA PT', right_on=' Term')\n",
    "\n",
    "hlt_manual = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_manually_annotated_hlt_effects.xls', index=False)\n",
    "hlt_manual.rename(columns={'Annotated MedDRA HLT': 'HLT'}, inplace=True)\n",
    "hlt_manual['HLT'] = hlt_manual['HLT'].apply(lambda x: x.upper())\n",
    "hlt_manual.drop(columns=['Annotated MedDRA HLT Code'])\n",
    "\n",
    "known_merged = pd.concat([known_merged, hlt_manual], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in directory_list:\n",
    "         \n",
    "    data = dirs[directory]\n",
    "    print('now starting {}'.format(directory))\n",
    "    \n",
    "    # Find associations\n",
    "    all_associations = analysis_functions.find_all_associations(basedir + '/ae_target_links/output/' + data['dir'])\n",
    "    assoc_df, sign_df = analysis_functions.find_associations(basedir + '/ae_target_links/output/' + data['dir'], min_n = data['min_n'], target_info=target_info, lr=data['lr'], pv=data['pv'])\n",
    "    print('found associations')\n",
    "        \n",
    "    # Promiscuity plots\n",
    "    analysis_functions.do_promiscuity_plots(sign_df, output_dir=basedir + '/ae_target_links/output/' + data['dir'])\n",
    "    print('done promiscuity plots')\n",
    "    \n",
    "    # Calculate Positive predictive value\n",
    "    sign_df['PPV'] = sign_df.apply(lambda x: analysis_functions.calculate_ppv(x), axis=1)\n",
    "    \n",
    "    # Find top associations\n",
    "    top_df = sign_df.loc[(sign_df['Likelihood Ratio']>=data['top_lr'])&(sign_df['corrected p-value']<=data['top_pv'])&(sign_df['PPV']>=data['ppv'])&(sign_df['ae_hit_rate']>=data['hr']),:]\n",
    "    print('found top df')\n",
    "    \n",
    "    # Make colour dict only for specified directory, keeps colours consistent across plots\n",
    "    if directory == args.colour_dict_dir:\n",
    "        if not os.path.exists(basedir + '/analysis/data/{}'.format(args.colour_dict_filename)):\n",
    "            analysis_functions.do_heatmap_dict(assoc_df = sign_df, meddra_hier= meddra_hier_selection, colour_dict_loc = basedir + '/analysis/data/{}'.format(args.colour_dict_filename))\n",
    "            print('done new colour dict')\n",
    "        else:\n",
    "            print('not done new colour dict')\n",
    "    \n",
    "    # Recall and positive predictive value\n",
    "    analysis_functions.do_pr_plot_and_txt(all_associations_df=assoc_df, meddra_hier=meddra_hier_selection, known_merged=known_merged, pv_cutoffs=[0.1,0.05,0.01,0.001], y_lim=0.15, x_lim=data['precision_display'], output_loc=basedir + '/ae_target_links/output/' + data['dir'])\n",
    "    print('done pr plots')\n",
    "    # Plot distributions of pvalues and LRs\n",
    "    analysis_functions.plot_pv_lr_dist(associations_df = assoc_df, meddra_hier=meddra_hier_selection, known_merged=known_merged, output_dir=basedir + '/ae_target_links/output/' + data['dir'])\n",
    "    print('done pv lr distributions')\n",
    "\n",
    "    # Heatmaps\n",
    "    analysis_functions.do_heatmap(assoc_df=top_df, meddra_hier=meddra_hier_selection, colour_dict_loc=basedir + '/analysis/data/{}'.format(data['colour_dict']), output_loc=basedir + '/ae_target_links/output/'+ data['dir'], output_filename_conditions=data['top_conditions_string'], clustering_method='complete')\n",
    "    analysis_functions.do_soc_donut(assoc_df=top_df, meddra_hier=meddra_hier_selection, colour_dict_loc=basedir + '/analysis/data/{}'.format(data['colour_dict']), output_loc=basedir + '/ae_target_links/output/'+ data['dir'], output_filename_conditions=data['top_conditions_string'], sizes=data['donut_sizes'], white_txt_nrs=data['donut_white'])\n",
    "    analysis_functions.do_atc_bar_plot(assoc_df=all_associations, all_atc_codes_loc=all_atc_codes_loc, small_molecule_atc_codes_loc=small_molecule_atc_codes_loc, output_loc=basedir + '/ae_target_links/output/'+ data['dir'])\n",
    "    print('done heatmaps and atc')\n",
    "    \n",
    "    # Overall Recall\n",
    "    recall_info = [analysis_functions.overall_recall(associations_df=assoc_df, lr=thresholds[0], pv=thresholds[1], known_merged=known_merged, meddra_hier=meddra_hier_selection) for thresholds in [(2,0.01), (2,0.05), (1,1.1)]]\n",
    "        \n",
    "    current_date = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "    with open(basedir + '/ae_target_links/output/' + data['dir'] + '/{}_overall_recall.txt'.format(current_date), 'w') as f:\n",
    "        f.write('\\n'.join(recall_info))\n",
    "    print('done overall recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
