{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import analysis_functions\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--faers_dir\", type=str, help=\"output directory for FAERS\")\n",
    "parser.add_argument(\"--sider_dir\", type=str, help=\"output directory for SIDER\")\n",
    "parser.add_argument(\"--dest_dir\", type=str, help=\"destination directory for the figures, in basedir/analysis\")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/scratch/ias41/ae_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_dir = basedir + f\"/analysis/results/{args.dest_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir + '/analysis/data/dirs_info.pkl', 'rb') as f:\n",
    "    dirs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and info needed for the analysis\n",
    "\n",
    "# Target information\n",
    "target_info = pd.read_csv(basedir + '/ae_target_links/data/target_names.txt', sep='\\t')\n",
    "target_info = target_info.loc[target_info['accession_organism']=='Homo sapiens',:]\n",
    "\n",
    "# Target classification\n",
    "chembl_target_classification = pd.read_csv(basedir + '/analysis/data/target_classification_all_levels_r.txt', sep = '\\t')\n",
    "\n",
    "# MedDRA hierchy\n",
    "meddra_hier = pd.read_excel(basedir + '/analysis/data/all_faers_and_sider_aes_hier_output.xlsx', skiprows=4)\n",
    "meddra_hier_selection = meddra_hier.loc[meddra_hier['Primary SOC']=='Y',[' Term','HLT','SOC']].drop_duplicates()\n",
    "meddra_hier_selection['HLT'] = meddra_hier_selection['HLT'].apply(lambda x: x.upper())\n",
    "\n",
    "# ATC codes\n",
    "all_atc_codes_loc = basedir + '/faers_sider_comparison/data/atc_all.txt'\n",
    "small_molecule_atc_codes_loc = basedir + '/faers_sider_comparison/data/atc_small_molecules.txt'\n",
    "\n",
    "# Previously reported associations\n",
    "# Known associations, merge with known hierarchy HLT\n",
    "known_associations = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_annotated_effects.xls')\n",
    "known_associations['Annotated MedDRA PT'] = known_associations['Annotated MedDRA PT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_annotated_effects_for_hierarchy_output.xlsx', skiprows=4)\n",
    "known_meddra_hier['PT'] = known_meddra_hier['PT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier[' Term'] = known_meddra_hier[' Term'].apply(lambda x: x.upper())\n",
    "known_meddra_hier['HLT'] = known_meddra_hier['HLT'].apply(lambda x: x.upper())\n",
    "known_meddra_hier_selection = known_meddra_hier.loc[known_meddra_hier['Primary SOC']=='Y',['PT','HLT',' Term']].drop_duplicates()\n",
    "known_merged = known_associations.merge(known_meddra_hier_selection, left_on='Annotated MedDRA PT', right_on=' Term')\n",
    "\n",
    "hlt_manual = pd.read_excel(basedir + '/prev_reported_safety_associations/data/safety_meddra_manually_annotated_hlt_effects.xls', index=False)\n",
    "hlt_manual.rename(columns={'Annotated MedDRA HLT': 'HLT'}, inplace=True)\n",
    "hlt_manual['HLT'] = hlt_manual['HLT'].apply(lambda x: x.upper())\n",
    "hlt_manual.drop(columns=['Annotated MedDRA HLT Code'])\n",
    "\n",
    "known_merged = pd.concat([known_merged, hlt_manual], sort=False).reset_index(drop=True)\n",
    "known_tuples = set([(x[1]['Accession'], x[1]['HLT']) for x in known_merged.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faers_data = dirs[args.faers_dir]\n",
    "sider_data = dirs[args.sider_dir]\n",
    "\n",
    "sider_all = analysis_functions.find_all_associations(basedir + '/ae_target_links/output/' + sider_data['dir'], min_n=sider_data['min_n'])\n",
    "faers_all = analysis_functions.find_all_associations(basedir + '/ae_target_links/output/' + faers_data['dir'], min_n=faers_data['min_n'])\n",
    "\n",
    "# Load main info from directories\n",
    "faers_pos, faers_sign =  analysis_functions.find_associations(basedir + '/ae_target_links/output/' + faers_data['dir'], min_n=faers_data['min_n'], lr=faers_data['lr'], pv=faers_data['pv'], target_info=target_info)\n",
    "sider_pos, sider_sign = analysis_functions.find_associations(basedir + '/ae_target_links/output/' + sider_data['dir'], min_n=sider_data['min_n'], lr=sider_data['lr'], pv=sider_data['pv'], target_info=target_info)\n",
    "\n",
    "# Calculate Positive predictive value\n",
    "faers_sign['PPV'] = faers_sign.apply(lambda x: analysis_functions.calculate_ppv(x), axis=1)\n",
    "sider_sign['PPV'] = sider_sign.apply(lambda x: analysis_functions.calculate_ppv(x), axis=1)\n",
    "\n",
    "# Find top associations\n",
    "faers_top = faers_sign.loc[(faers_sign['Likelihood Ratio']>=faers_data['top_lr'])&(faers_sign['corrected p-value']<=faers_data['top_pv'])&(faers_sign['PPV']>=faers_data['ppv'])&(faers_sign['ae_hit_rate']>=faers_data['hr']),:]\n",
    "sider_top = sider_sign.loc[(sider_sign['Likelihood Ratio']>=sider_data['top_lr'])&(sider_sign['corrected p-value']<=sider_data['top_pv'])&(sider_sign['PPV']>=sider_data['ppv'])&(sider_sign['ae_hit_rate']>=sider_data['hr']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prevalence(x):\n",
    "    ae_prevalence = (x['nr compounds with AE'] / x['nr compounds'])\n",
    "    return ae_prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sider_sign['ae_prevalence'] = sider_sign.apply(calculate_prevalence, axis=1)\n",
    "faers_sign['ae_prevalence'] = faers_sign.apply(calculate_prevalence, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_improvement(x): \n",
    "    improvement =x['PPV'] - x['ae_prevalence']\n",
    "    return improvement\n",
    "for df in [faers_sign, sider_sign]:\n",
    "    df['Value-added PPV'] = df.apply(calculate_improvement, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv(destination_dir + '/annotations_sign_va-PPV.txt', sep='\\t')\n",
    "annotations = []\n",
    "for row in annotations_df.iterrows():\n",
    "    annotations.append((row[1]['Annotation'], (float(row[1]['x']),float(row[1]['y'])), (float(row[1]['x_text']),float(row[1]['y_text']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_custom_df = pd.read_csv(destination_dir + '/annotations_sign_custom_va-PPV.txt', sep='\\t')\n",
    "annotations_custom = []\n",
    "for row in annotations_custom_df.iterrows():\n",
    "    annotations_custom.append((row[1]['Annotation'], (float(row[1]['x']),float(row[1]['y'])), (float(row[1]['x_text']),float(row[1]['y_text']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_functions.make_sign_target_overview_table(faers_top, 'FAERS', sider_top, 'SIDER', chembl_target_classification, known_merged, output_loc = destination_dir)\n",
    "print('done comparison table of significant targets')\n",
    "\n",
    "analysis_functions.do_hit_rate_ppv_plot(df2=faers_sign, df2_name='FAERS', df2_color='sandybrown', df1=sider_sign, df1_name='SIDER', df1_color='steelblue', output_dir=destination_dir, annotations=annotations, additional_filename='_significant')\n",
    "analysis_functions.do_hit_rate_ppv_plot(df2=faers_sign, df2_name='FAERS', df2_color='sandybrown', df1=sider_sign, df1_name='SIDER', df1_color='steelblue', output_dir=destination_dir, additional_filename='_significant_no_annot')\n",
    "analysis_functions.do_hit_rate_ppv_plot(df2=faers_sign, df2_name='FAERS', df2_color='sandybrown', df1=sider_sign, df1_name='SIDER', df1_color='steelblue', output_dir=destination_dir, annotations=annotations_custom, additional_filename='_significant_custom_annot')\n",
    "\n",
    "print('done hit rate PPV plot')\n",
    "\n",
    "analysis_functions.do_cumulative_recall(df1=faers_pos, df1_name='FAERS', df1_color='sandybrown', df2=sider_pos, df2_name='SIDER', df2_color='darkslateblue', meddra_hier=meddra_hier_selection, sort_by_columns=['corrected p-value','Likelihood Ratio'], ascending=[True,False], known_merged=known_merged, output_loc=destination_dir)\n",
    "print('done cumulative recall')\n",
    "\n",
    "analysis_functions.do_target_class_bar_plot(df1=sider_all, df1_name='SIDER', df1_color='steelblue', df2=faers_all, df2_name='FAERS', df2_color='sandybrown', chembl_target_classification=chembl_target_classification, safety_targets=set(known_merged['Accession']), df3_name='Previously reported safety targets', df3_color='darkgrey', output_loc=destination_dir)\n",
    "analysis_functions.do_target_class_bar_plot_without_safety(df1=sider_all, df1_name='SIDER', df1_color='steelblue', df2=faers_all, df2_name='FAERS', df2_color='sandybrown', chembl_target_classification=chembl_target_classification, output_loc=destination_dir)\n",
    "print('done target class bar plots')\n",
    "\n",
    "analysis_functions.plot_actives_per_target(assoc_df1=faers_all, dataset1_name='FAERS', df1_color='sandybrown', assoc_df2=sider_all, dataset2_name='SIDER', df2_color='steelblue', output_loc=destination_dir)\n",
    "\n",
    "with open(destination_dir + '/actives_count_describe.txt', 'w') as f:\n",
    "    f.write('Number of active compounds per protein (FAERS):\\n' + str(faers_pos[['accession','nr compounds active']].drop_duplicates().describe()) + f\"\\nmedian: {np.median(faers_pos[['accession','nr compounds active']]['nr compounds active'])}\")\n",
    "    f.write('\\nNumber of active compounds per protein (SIDER):\\n' + str(sider_pos[['accession','nr compounds active']].drop_duplicates().describe()) + f\"\\nmedian: {np.median(sider_pos[['accession','nr compounds active']]['nr compounds active'])}\")\n",
    "\n",
    "print('done histograms of actives per target')\n",
    "            \n",
    "analysis_functions.do_atc_bar_plot_three_datasets(assoc_df2=faers_all, df2_name='FAERS', df2_color='sandybrown', assoc_df1=sider_all, df1_name='SIDER', df1_color='steelblue', all_atc_codes_loc=all_atc_codes_loc, small_molecule_atc_codes_loc=small_molecule_atc_codes_loc, output_loc=destination_dir)\n",
    "print('done combined ATC plot')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write number of targets and significant AE-associations\n",
    "sign_combined = pd.concat([faers_sign, sider_sign])\n",
    "sign_combined['Adverse Event'] = sign_combined['Adverse Event'].apply(lambda x: x.upper())\n",
    "nr_sign_aes = len(set(sign_combined['Adverse Event']))\n",
    "nr_sign_targets = len(set(sign_combined['accession']))\n",
    "\n",
    "top_combined = pd.concat([faers_top, sider_top])\n",
    "top_combined['Adverse Event'] = top_combined['Adverse Event'].apply(lambda x: x.upper())\n",
    "nr_top_aes = len(set(top_combined['Adverse Event']))\n",
    "nr_top_targets = len(set(top_combined['accession']))\n",
    "\n",
    "with open(destination_dir + '/nr_of_aes_counts.txt', 'w') as f:\n",
    "    f.write(f\"Number of unique significant targets: {nr_sign_targets}\")\n",
    "    f.write(f\"\\nNumber of unique significant AEs: {nr_sign_aes}\")\n",
    "    f.write(f\"\\nTop is defined as PPV => {faers_data['ppv']} (SIDER) or {sider_data['ppv']} (FAERS) and AE hit rate => {faers_data['hr']} (FAERS) or {sider_data['hr']} (SIDER).\")\n",
    "    f.write(f\"\\nNumber of unique top targets: {nr_top_targets}\")\n",
    "    f.write(f\"\\nNumber of unique top AEs: {nr_top_aes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([faers_sign, sider_sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Adverse Event'] = combined['Adverse Event'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(combined['Adverse Event']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do hit rate -PPV plot of known associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Positive predictive value\n",
    "faers_merged = faers_sign.merge(meddra_hier_selection, left_on='Adverse Event', right_on=' Term')\n",
    "sider_merged = sider_sign.merge(meddra_hier_selection, left_on='Adverse Event', right_on=' Term')\n",
    "\n",
    "def find_known(row):\n",
    "    if ((row['accession'],row['HLT'])) in known_tuples:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "faers_merged['known'] = faers_merged.apply(find_known, axis=1)\n",
    "sider_merged['known'] = sider_merged.apply(find_known, axis=1)\n",
    "\n",
    "faers_known = faers_merged.loc[faers_merged['known']==1]\n",
    "sider_known = sider_merged.loc[sider_merged['known']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_known_df = pd.read_csv(destination_dir + '/annotations_known_va-PPV.txt', sep='\\t')\n",
    "annotations_known = []\n",
    "for row in annotations_known_df.iterrows():\n",
    "    annotations_known.append((row[1]['Annotation'], (float(row[1]['x']),float(row[1]['y'])), (float(row[1]['x_text']),float(row[1]['y_text']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_functions.do_hit_rate_ppv_plot(faers_known, 'FAERS', 'orange', sider_known, 'SIDER', 'blue', output_dir=destination_dir, annotations=annotations_known, additional_filename='_known', alpha=0.6)\n",
    "analysis_functions.do_hit_rate_ppv_plot(faers_known, 'FAERS', 'orange', sider_known, 'SIDER', 'blue', output_dir=destination_dir, additional_filename='_known_no_annot', alpha=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
